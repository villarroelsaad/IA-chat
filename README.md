# IA-chat: Chat assistant with local fallback

Demo project providing a Python (Flask) backend and a React + Vite frontend to interact with a chatbot.

The backend attempts to use Google GenAI (Gemini) via `google.genai` if available and an API key is configured. Otherwise it includes a simple fallback bot for local testing.

---

## üìã Project structure

- `back/` ‚Äî Python (Flask) backend
  - `server.py` ‚Äî HTTP API with `/health`, `/chat` and `/upload-file` endpoints
  - `chat/chat.py` ‚Äî Bot implementation: integration with `google.genai` and `SimpleFallbackBot`
  - `test_api.py` ‚Äî Script to test the `/chat` endpoint
  - `requirements.txt` ‚Äî Python dependencies
  - `Dockerfile`, `docker-compose.yml` ‚Äî Files to containerize the project

- `front/` ‚Äî React + TypeScript (Vite) frontend
  - `src/` ‚Äî React app code
  - `services/chat.ts` ‚Äî Requests to the backend (`/chat` and `/upload-file`)
  - `package.json` ‚Äî Scripts and dev dependencies

---

## üí° What this project does

- Provides a REST API that receives messages and returns replies generated by a language model (if your environment has access to Google GenAI *Gemini*).
- If no API access is available, the backend uses a `SimpleFallbackBot` with basic rules (e.g., recognize the word "dog" or a number to calculate paws).
- Allows uploading files (`.txt`, `.pdf`, `.docx`) that are converted to text and used as context for responses.
- Data is currently saved in memory. You can modify the FILE_TEXTS variable in server.py to integrate your database connection.

---

## Requirements üöß

- Python 3.8+ (backend)
- Node.js (v16+ recommended) and npm for the frontend
- (Optional) Docker and docker-compose to run both services locally

Key dependencies are listed in `back/requirements.txt` and `front/package.json`.

---

## Environment variables üå±

- `GEMINI_API_KEY` ‚Äî (optional) Google GenAI key if you want to use the Gemini service.
- `GEMINI_MODEL` ‚Äî (optional) default model to use (example: `gemini-2.5-flash`).
- `PORT` ‚Äî Port for the backend (default: `8000`).
- `VITE_BACKEND_URL` ‚Äî (frontend) base URI for the backend (example: `http://localhost:8000`).

You can create a `.env` file inside `back/` to store these variables if you want. The project loads `.env` if `python-dotenv` is installed.

---

## Installation and running (without Docker) ‚öôÔ∏è

### Backend (Python)

1. Open a terminal and change to the `back/` folder:

```powershell
cd back
```

2. Create a virtual environment (recommended) and install dependencies:

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

3. Optionally add `GEMINI_API_KEY` to a `.env` file or export it in your environment.

4. Run the server:

```powershell
python server.py
```

The backend will be available at `http://localhost:8000`.

### Frontend (React + Vite)

1. Install dependencies and start the development server:

```powershell
cd front
npm install
npm run dev
```

The development frontend is typically available at `http://localhost:5173` (or the port Vite reports) and will connect to the backend at `http://localhost:8000` unless you set `VITE_BACKEND_URL`.

---

## Running with Docker (recommended for quick testing) üê≥

From the repository root, there is a `docker-compose.yml` that launches both backend and frontend services:

```powershell
docker-compose up --build
```

After building, the backend is typically at `http://localhost:8000` and the frontend at `http://localhost:3000`.

---

## Main endpoints üîå

- `GET /` ‚Äî Health check, returns `{"status":"ok"}`.
- `POST /chat` ‚Äî Send a user message (JSON `{"message": "..."}`) and receive `{"reply": "..."}`.
- `POST /upload-file` ‚Äî `multipart/form-data` with a `file` field to upload text (reads text from `.txt`, `.pdf`, `.docx` and stores it in memory for context). Returns `{"ok": true, "filename": "..."}`.

Example curl call:

```powershell
curl -X POST http://localhost:8000/chat -H "Content-Type: application/json" -d '{"message":"I have 2 dogs"}'

# Expected response:
# {"reply": "If you have 2 dogs, there are 8 paws in total (assuming 4 paws per dog)."}
```

---

## Quick local test üß™

1. Start `server.py`.
2. From the `back/` folder run `python test_api.py` to test the `/chat` endpoint.

---

## Security notes and limitations ‚ö†Ô∏è

- Uploaded file text is stored in memory (`FILE_TEXTS`) ‚Äî in production you should use persistent storage or a database.
- CORS is wide open for development. In production, restrict allowed origins.
- `SimpleFallbackBot` is intentionally simple for demonstrating behavior without accessing the real API.
- If you use `google.genai`, make sure your key is configured and you're aware of usage costs and policies.

---

## Contributing ü§ù

If you'd like to contribute:

1. Fork the repository.
2. Create a branch with your feature or fix.
3. Open a pull request describing your changes.

Issues and PRs are welcome for improvements, additional tests, or fixes.

---

## FAQ / Tips üí°

- How do I test without installing the Gemini API? ‚Äî You don't need the key: the backend will fall back to `SimpleFallbackBot`, letting you test uploads and general behavior locally.
- How do I point the frontend to a different backend? ‚Äî Set `VITE_BACKEND_URL` in your environment or a `.env` file when starting Vite.

---
